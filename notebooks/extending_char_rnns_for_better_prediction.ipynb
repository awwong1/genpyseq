{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extending Sequence Prediction Using Character Level Recurrent Networks\n",
    "\n",
    "*The code in this notebook may be unnecessarily complicated, due to trial and error*\n",
    "\n",
    "We extend the approach outlined in `char_rnn_one_file_code_gen.ipynb` to improve efficiency and to accomodate other recurrent cells. Notably:\n",
    "\n",
    "* Training will use multiple files, instead of a single file\n",
    "* Validation sets will be introduced to avoid overfitting on our training data\n",
    "* We will have our model utilize mini-batches to speed up training\n",
    "\n",
    "Our outlined task is still the same.\n",
    "\n",
    "**Given a sequence of characters, predict the next likely character in the sequence.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import random\n",
    "from json import load\n",
    "from math import floor\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "\n",
    "We will be training on a set of 180 preprocessed Python files (and validating on a set of 20 other files) arbitrarily sampled from [GitHub BigQuery Python Extracts](https://bigquery.cloud.google.com/table/fh-bigquery:github_extracts.contents_py_201802snap?pli=1).\n",
    "\n",
    "We limit the characters that our neural network can produce to a subset of standard ASCII.\n",
    "* `ORD 2*, 3*, 9, 10, 32-126`\n",
    "  * `ORD 0` for padding (special, used in batch_size > 1 with variable length sequences)\n",
    "  * `ORD 2` for start of text (special, never predicted)\n",
    "  * `ORD 3` for end of text (special, prediction ends)\n",
    "  * `ORD 9` horizontal tab \"\\t\"\n",
    "  * `ORD 10` NL line feed, new line \"\\n\"\n",
    "  * `ORD 32-126` Space, Punctuation, Digits, English Letters\n",
    "\n",
    "NOTE: The full dataset contains files written using non standard characters. For the models in this notebook, we ensure that all Python files within our dataset are composed only of ASCII characters that we accept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: '\\x00'\n",
      "2: '\\x02'\n",
      "3: '\\x03'\n",
      "9: '\\t'\n",
      "10: '\\n'\n",
      "32: ' '\n",
      "!\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Num Training Files: 180\n",
      "Num Validation Files: 20\n",
      "SANITY Training Files: 1\n"
     ]
    }
   ],
   "source": [
    "# Possible Characters for neural network\n",
    "VALID_UNICODE_IDS = (0, 2, 3, 9, 10) + tuple(range(32, 127))\n",
    "for uid in VALID_UNICODE_IDS:\n",
    "    if uid <= 32:\n",
    "        print(\"{}: {}\".format(uid, repr(chr(uid))))\n",
    "        continue\n",
    "    print(chr(uid), end=\"\")\n",
    "print()\n",
    "\n",
    "# Special Characters\n",
    "PAD = chr(0)\n",
    "FILE_START = chr(2)\n",
    "FILE_END = chr(3)\n",
    "\n",
    "CHARACTERS = set(chr(id) for id in VALID_UNICODE_IDS)\n",
    "INT2CHAR = dict(enumerate(CHARACTERS))\n",
    "CHAR2INT = {char: idx for idx, char in INT2CHAR.items()}\n",
    "\n",
    "with open(\"./data/train.json\", \"r\") as f:\n",
    "    training_data = load(f)\n",
    "with open(\"./data/validate.json\", \"r\") as f:\n",
    "    validation_data = load(f)\n",
    "\n",
    "print(\"~\" * 25)\n",
    "print(\"Num Training Files: {}\".format(len(training_data)))\n",
    "print(\"Num Validation Files: {}\".format(len(validation_data)))\n",
    "\n",
    "# SANITY_CHECK, MEMORIZE ONE FILE\n",
    "with open(\"./data/test.py\", \"r\") as f:\n",
    "    text = f.read()\n",
    "training_data = ((FILE_START, ) + tuple(text) + (FILE_END,),)\n",
    "print(\"SANITY Training Files: {}\".format(len(training_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's randomly take a look at what is contained within our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0002\"\"\"Predict Test\"\"\"\n",
      "import sys\n",
      "from os import getcwd\n",
      "\n",
      "def main():\n",
      "    sys.stdout.write(getcwd())\n",
      "    for i in range(0, 10):\n",
      "        print(\"{} : Boop\".format(i), i)\n",
      "    return False\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "\u0003\n"
     ]
    }
   ],
   "source": [
    "train_sample = random.sample(training_data, 1)[0]\n",
    "print(\"\".join(train_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching Sliding Window Algorithm\n",
    "\n",
    "Extending from the previously created sliding window algorithm:\n",
    "\n",
    "* Given some iterable, we want a generator that yields X, Y pairs for evaluation.\n",
    "* We want a sequence of a given context length as X, and the next character as Y.\n",
    "\n",
    "We want our sliding window algorithm to yield these pairs in batches, for more efficient computation. Iterable is no longer a single file, but an iterator over multiple files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_sliding_window_generator(iterable_files, batch_size, max_window_size=None, output_seq=False, gen_forever=True):\n",
    "    \"\"\"Sliding window generator for batching files of ASCII characters\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        data_pairs = []\n",
    "\n",
    "        for iterable in iterable_files:\n",
    "            if max_window_size is None:\n",
    "                window_size = len(iterable)\n",
    "            else:\n",
    "                window_size = max_window_size\n",
    "\n",
    "            # edge case inbetween files\n",
    "            existing_window_sizes = [len(x) for x, _ in data_pairs]\n",
    "            if existing_window_sizes and not all(size == window_size for size in existing_window_sizes):\n",
    "                window_size = min(existing_window_sizes)\n",
    "\n",
    "            for window_idx in range(1, len(iterable)):\n",
    "                x = iterable[:window_idx]\n",
    "                if len(x) > window_size:\n",
    "                    x = x[-window_size:]\n",
    "                elif len(x) < window_size:\n",
    "                    x = (PAD,) * (window_size - len(x)) + tuple(x)\n",
    "                y = iterable[window_idx]\n",
    "                if output_seq:\n",
    "                    y = (x + (y,))[-window_size:]\n",
    "                data_pairs.append((x, y))\n",
    "\n",
    "            random.shuffle(data_pairs)\n",
    "            while len(data_pairs) >= batch_size:\n",
    "                to_yield = data_pairs[:batch_size]\n",
    "                data_pairs = data_pairs[batch_size:]\n",
    "                \n",
    "                # order by sequence lengths\n",
    "                sorted_to_yield = sorted(to_yield, key=lambda kv: kv[0].count(PAD))\n",
    "                yield sorted_to_yield, np.array([len(x) - x.count(PAD) for x, _ in sorted_to_yield])\n",
    "\n",
    "        # To ensure all batches have the same size and no data is left unused, re-sample last file\n",
    "        if data_pairs:\n",
    "            assert len(data_pairs) < batch_size\n",
    "            cleanup_data_pairs = []\n",
    "            for window_idx in range(1, len(iterable)):\n",
    "                x = iterable[:window_idx]\n",
    "                if len(x) > window_size:\n",
    "                    x = x[-window_size:]\n",
    "                elif len(x) < window_size:\n",
    "                    x = (PAD,) * (window_size - len(x)) + tuple(x)\n",
    "                y = iterable[window_idx]\n",
    "                if output_seq:\n",
    "                    y = (x + (y,))[-window_size:]\n",
    "                cleanup_data_pairs.append((x, y))\n",
    "            cleanup_data_pairs = random.sample(cleanup_data_pairs, batch_size - len(data_pairs))\n",
    "            data_pairs.extend(cleanup_data_pairs)\n",
    "            # development, check for correctness\n",
    "            assert len(data_pairs) == batch_size\n",
    "            data_pairs.sort(key=lambda kv: kv[0].count(PAD))\n",
    "            yield data_pairs, np.array([len(x) - x.count(PAD) for x, _ in data_pairs])\n",
    "                \n",
    "        if not gen_forever:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the first 3 generator outputs, given a batch size of 2 and a maximum window size of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "(('a', 'i', 'n', '(', ')', ':', '\\n', ' ', ' ', ' ', ' ', 's', 'y', 's', '.'), 's')\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Batch 1\n",
      "(('e', 't', 'c', 'w', 'd', '\\n', '\\n', 'd', 'e', 'f', ' ', 'm', 'a', 'i', 'n'), '(')\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Batch 2\n",
      "(('i', 'n', '_', '_', '\"', ':', '\\n', ' ', ' ', ' ', ' ', 'm', 'a', 'i', 'n'), '(')\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Padding Example\n",
      "(('\\x00', '\\x00', '\\x00', '\\x00', '\\x00', '\\x00', '\\x00', '\\x00', '\\x00', '\\x00', '\\x02', '\"', '\"', '\"', 'P'), 'r')\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "max_window_size = 15\n",
    "\n",
    "gen = batch_sliding_window_generator(training_data, batch_size, max_window_size)\n",
    "for i in range(3):\n",
    "    batch, _ = next(gen)\n",
    "    print(\"Batch {}\".format(i))\n",
    "    print(*batch, sep=\"\\n\")\n",
    "    print(\"~\"*25)\n",
    "\n",
    "print(\"Padding Example\")\n",
    "searching = True\n",
    "while searching:\n",
    "    batch, _ = next(gen)\n",
    "    for x, y in batch:\n",
    "        if PAD in x:\n",
    "            searching = False\n",
    "            break\n",
    "print((x, y,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how changing the `batch_size` and `max_window_size` parameters of the generator influence the values we use to train our neural network.\n",
    "\n",
    "Setting `batch_size=1` and `max_window_size=None` is most computationally expensive option, which has equivalent functionality to the batching algorithm defined in `char_rnn_one_file_code_gen.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking batch_size=1, max_window_size=10:\n",
      " • 220 number of batches\n",
      "   • 220 batches have window size 10\n",
      " • 220 number of examples\n",
      "   • 1 examples have seq len 1\n",
      "   • 1 examples have seq len 2\n",
      "   • 1 examples have seq len 3\n",
      "   • 1 examples have seq len 4\n",
      "   • 1 examples have seq len 5\n",
      "   • 1 examples have seq len 6\n",
      "   • 1 examples have seq len 7\n",
      "   • 1 examples have seq len 8\n",
      "   • 1 examples have seq len 9\n",
      "   • 211 examples have seq len 10\n",
      "9 ('\\x00', '\\x02', '\"', '\"', '\"', 'P', 'r', 'e', 'd', 'i') c\n",
      "2 ('\\x00', '\\x00', '\\x00', '\\x00', '\\x00', '\\x00', '\\x00', '\\x00', '\\x02', '\"') \"\n",
      "1 ('\\x00', '\\x00', '\\x00', '\\x00', '\\x00', '\\x00', '\\x00', '\\x00', '\\x00', '\\x02') \"\n",
      "4 ('\\x00', '\\x00', '\\x00', '\\x00', '\\x00', '\\x00', '\\x02', '\"', '\"', '\"') P\n",
      "5 ('\\x00', '\\x00', '\\x00', '\\x00', '\\x00', '\\x02', '\"', '\"', '\"', 'P') r\n",
      "10 (' ', ' ', ' ', 'm', 'a', 'i', 'n', '(', ')', '\\n') \u0003\n",
      "3 ('\\x00', '\\x00', '\\x00', '\\x00', '\\x00', '\\x00', '\\x00', '\\x02', '\"', '\"') \"\n",
      "6 ('\\x00', '\\x00', '\\x00', '\\x00', '\\x02', '\"', '\"', '\"', 'P', 'r') e\n",
      "7 ('\\x00', '\\x00', '\\x00', '\\x02', '\"', '\"', '\"', 'P', 'r', 'e') d\n",
      "8 ('\\x00', '\\x00', '\\x02', '\"', '\"', '\"', 'P', 'r', 'e', 'd') i\n"
     ]
    }
   ],
   "source": [
    "# ensure that the dynamic batch window size logic works for arbitrary sequence lengths\n",
    "\n",
    "# This takes some time to run. Set this to 0 if you understand the batching generator functionality\n",
    "# check_batch_size = 0\n",
    "check_batch_size = 1\n",
    "# check_batch_size = 100\n",
    "\n",
    "# If set to None, window sizes will default to the number of characters in the file\n",
    "check_window_size = 10\n",
    "# check_window_size = None\n",
    "\n",
    "if check_batch_size:\n",
    "    print(\"Checking batch_size={}, max_window_size={}:\".format(check_batch_size, check_window_size))\n",
    "    gen = batch_sliding_window_generator(\n",
    "        training_data, check_batch_size, max_window_size=check_window_size, gen_forever=False)\n",
    "\n",
    "    batch_windows = {}\n",
    "    all_item_seqs_lens = {}\n",
    "    for batch, item_seq_lens in gen:\n",
    "        x, _ = batch[0]\n",
    "        batch_window_size = len(x)\n",
    "        assert all(batch_window_size == len(x) for x, _ in batch)\n",
    "        batch_windows[batch_window_size] = batch_windows.get(batch_window_size, 0) + 1\n",
    "        for item_seq_len in item_seq_lens:\n",
    "            all_item_seqs_lens[item_seq_len] = all_item_seqs_lens.get(item_seq_len, 0) + 1\n",
    "    print(\" • {} number of batches\".format(sum(batch_windows.values())))\n",
    "    for window_size, num_batches in sorted(batch_windows.items(), key=lambda kv: kv[1]):\n",
    "        print(\"   • {} batches have window size {}\".format(num_batches, window_size))\n",
    "    print(\" • {} number of examples\".format(sum(all_item_seqs_lens.values())))\n",
    "    for seq_len_size, num_examples in sorted(all_item_seqs_lens.items(), key=lambda kv: kv[0]):\n",
    "        print(\"   • {} examples have seq len {}\".format(num_examples, seq_len_size))\n",
    "\n",
    "    gen = batch_sliding_window_generator(\n",
    "        training_data, check_batch_size, max_window_size=check_window_size, gen_forever=False)\n",
    "    for batch, seqlens in gen:\n",
    "        for idx, xy in enumerate([e for e in batch if PAD in e[0] or FILE_END in e[1]]):\n",
    "            x, y = xy\n",
    "            print(seqlens[idx], x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An additional tensor containing the original lengths of all the padded sequences is also outputted for each batch. It is sorted by length in decreasing order, as per the [pad_packed_sequence](https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pack_padded_sequence) documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Sequence 0 has length 212 (9 pad chars)\n",
      "X_Sequence 1 has length 104 (117 pad chars)\n",
      "X_Sequence 2 has length 89 (132 pad chars)\n",
      "X_Sequence 3 has length 76 (145 pad chars)\n",
      "X_Sequence 4 has length 62 (159 pad chars)\n",
      "X_Sequence 5 has length 49 (172 pad chars)\n",
      "X_Sequence 6 has length 46 (175 pad chars)\n",
      "X_Sequence 7 has length 44 (177 pad chars)\n",
      "X_Sequence 8 has length 42 (179 pad chars)\n",
      "X_Sequence 9 has length 21 (200 pad chars)\n"
     ]
    }
   ],
   "source": [
    "check_batch_size = 10\n",
    "check_window_size = None\n",
    "gen = batch_sliding_window_generator(\n",
    "    training_data, check_batch_size, max_window_size=check_window_size, gen_forever=False)\n",
    "\n",
    "batch, x_seqs_len = next(gen)\n",
    "x_seqs, _ = zip(*batch)\n",
    "\n",
    "for idx, x_seq in enumerate(x_seqs):\n",
    "    x_seq_len = x_seqs_len[idx].item()\n",
    "    print(\"X_Sequence {} has length {} ({} pad chars)\".format(idx, x_seq_len, len(x_seq) - x_seq_len))\n",
    "\n",
    "num_pads = len(x_seqs[0]) - x_seqs_len[0].item()\n",
    "# print(x_seqs[0][num_pads:][:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilize CUDA & GPU\n",
    "Training neural networks can be slow. It would be useful to utilize GPUs if we have them available to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n",
      " • Number of CUDA devices: 1\n",
      " • Current Device Name: TITAN Xp\n",
      " • Device CUDA Capability: (6, 1)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "HAS_GPU = False\n",
    "if torch.cuda.is_available():\n",
    "    HAS_GPU = True\n",
    "    print(\"CUDA is available\")\n",
    "    print(\" • Number of CUDA devices: {}\".format(torch.cuda.device_count()))\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\" • Current Device Name: {}\".format(torch.cuda.get_device_name(device)))\n",
    "    print(\" • Device CUDA Capability: {}\".format(torch.cuda.get_device_capability(device)))\n",
    "\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "\n",
    "# force GPU off.\n",
    "HAS_GPU = False\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Characters to Tensors\n",
    "\n",
    "Our batch of inputs and outputs must be converted into Tensors for training.\n",
    "\n",
    "We follow the default matrix convention used by the PyTorch comunity.\n",
    "\n",
    "> Tensor’s data will be of size `T x B x *`, where `T` is the length of the longest sequence and `B` is the batch size. \n",
    "\n",
    "To make a batch training example, we join a bunch our sequences of one-hot characters into a matrix of size `(window_size, batch_size, num_chars)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charseq_to_tensor(char_seq, num_chars=len(CHARACTERS)):\n",
    "    seq_size = len(char_seq)\n",
    "    seq_tensor = torch.zeros(seq_size, 1, num_chars, device=device)\n",
    "    for seq_idx, char in enumerate(char_seq):\n",
    "        seq_tensor[seq_idx][0][CHAR2INT[char]] = 1\n",
    "    return seq_tensor\n",
    "\n",
    "def batch_xy_to_tensor_xy(batch, num_chars=len(CHARACTERS)):\n",
    "    batch_size = len(batch)\n",
    "    window_size = max([len(x) for x, _ in batch])\n",
    "    assert all(len(x) == window_size for x, _ in batch)\n",
    "    \n",
    "    x_tensor = torch.zeros(window_size, batch_size, num_chars, device=device)\n",
    "    y_tensor = torch.zeros(1, batch_size, num_chars, device=device)\n",
    "\n",
    "    for batch_elm_idx, xy_pair in enumerate(batch):\n",
    "        x_char_seq, y_char = xy_pair\n",
    "        for seq_idx, x_char in enumerate(x_char_seq):\n",
    "            x_tensor[seq_idx][batch_elm_idx][CHAR2INT[x_char]] = 1\n",
    "        y_tensor[0][batch_elm_idx][CHAR2INT[y_char]] = 1\n",
    "    return x_tensor, y_tensor\n",
    "\n",
    "def batch_xy_to_tensor_xyseq(batch, num_chars=len(CHARACTERS)):\n",
    "    batch_size = len(batch)\n",
    "    window_size = max([len(x) for x, _ in batch])\n",
    "    assert all(len(x) == window_size for x, _ in batch)\n",
    "    \n",
    "    x_tensor = torch.zeros(window_size, batch_size, num_chars, device=device)\n",
    "    y_tensor = torch.zeros(window_size, batch_size, num_chars, device=device)\n",
    "\n",
    "    for batch_elm_idx, xy_pair in enumerate(batch):\n",
    "        x_char_seq, y_char_seq = xy_pair\n",
    "        for seq_idx, x_char in enumerate(x_char_seq):\n",
    "            x_tensor[seq_idx][batch_elm_idx][CHAR2INT[x_char]] = 1\n",
    "            y_tensor[seq_idx][batch_elm_idx][CHAR2INT[y_char_seq[seq_idx]]] = 1\n",
    "    return x_tensor, y_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensor inputs and outputs for the generator function we defined earlier are shown here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 1, max_window_size: 15\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "(' ', ' ', ' ', ' ', 's', 'y', 's', '.', 's', 't', 'd', 'o', 'u', 't', '.')\n",
      "torch.Size([15, 1, 100])\n",
      "'w'\n",
      "torch.Size([1, 1, 100])\n"
     ]
    }
   ],
   "source": [
    "gen = batch_sliding_window_generator(training_data, batch_size, max_window_size)\n",
    "\n",
    "batch, _ = next(gen)\n",
    "x = [item[0] for item in batch]\n",
    "y = [repr(item[1]) for item in batch]\n",
    "x_tensor, y_tensor = batch_xy_to_tensor_xy(batch)\n",
    "\n",
    "print(\"batch_size: {}, max_window_size: {}\".format(batch_size, max_window_size))\n",
    "print(\"~\" * 25)\n",
    "print(*x, sep=\"\\n\")\n",
    "print(x_tensor.size())\n",
    "print(*y, sep=\"\\n\")\n",
    "print(y_tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Network\n",
    "\n",
    "We are going to create our recurrent neural network. Rather than using our own pure recurrent neural network defined in the last notebook, we will be using the [recurrent layers](https://pytorch.org/docs/stable/nn.html#recurrent-layers) provided by PyTorch.\n",
    "* **RNN**: [Recurrent Neural Network](https://pytorch.org/docs/stable/nn.html#rnn)\n",
    "* **GRU**: [Gated Recurrent Unit](https://pytorch.org/docs/stable/nn.html#gru)\n",
    "* **LSTM**: [Long Short-Term Memory](https://pytorch.org/docs/stable/nn.html#lstm)\n",
    "\n",
    "There are some subtleties in the forward pass function, as we want to mask away the `PAD` characters so they do not influence our model results.\n",
    "\n",
    "Our model is composed of the following:\n",
    "0. Recurrent Layer (RNN/GRU/LSTM)\n",
    "1. Linear Layer\n",
    "2. Softmax Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, batch_size,\n",
    "                 hidden_size=128, recurrent_layer_type=\"RNN\", recurrent_layers=1, recurrent_dropout=0):\n",
    "        super(CharRNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.recurrent_num_layers = recurrent_layers\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        rn_kwargs = {\n",
    "            \"input_size\": input_size,\n",
    "            \"hidden_size\": hidden_size,\n",
    "            \"num_layers\": recurrent_layers,\n",
    "            \"dropout\": recurrent_dropout,\n",
    "        }\n",
    "\n",
    "        self.rn_type = recurrent_layer_type        \n",
    "        if recurrent_layer_type == \"RNN\":\n",
    "            self.input_to_rn = nn.RNN(**rn_kwargs)\n",
    "        elif recurrent_layer_type == \"LSTM\":\n",
    "            self.input_to_rn = nn.LSTM(**rn_kwargs)\n",
    "        elif recurrent_layer_type == \"GRU\":\n",
    "            self.input_to_rn = nn.GRU(**rn_kwargs)\n",
    "        else:\n",
    "            raise \"Invalid recurrent layer type: {}\".format(recurrent_layer_type)\n",
    "\n",
    "        \n",
    "        self.rn_to_output = nn.Linear(hidden_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, batched_input_chars, hidden):\n",
    "        # pack > recurrent network > unpack (packing not necessary for this task?)\n",
    "        # packed_input_seqs = nn.utils.rnn.pack_padded_sequence(input_seqs, input_seqs_len)\n",
    "        rn_outs, next_hidden = self.input_to_rn(batched_input_chars, hidden)\n",
    "        # unpacked_rn_outs, _ = nn.utils.rnn.pad_packed_sequence(rn_outs, padding_value=CHAR2INT[PAD])\n",
    "\n",
    "        if self.rn_type == \"LSTM\":\n",
    "            combined = torch.cat((rn_outs, next_hidden[0]), dim=2)\n",
    "        else:\n",
    "            combined = torch.cat((rn_outs, next_hidden), dim=2)\n",
    "        # send rn output through dense linear layer with softmax activation\n",
    "        pre_activated_output = self.rn_to_output(combined)\n",
    "        predicted_output = self.softmax(pre_activated_output)\n",
    "\n",
    "        return predicted_output, next_hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        if self.rn_type == \"LSTM\":\n",
    "            return (\n",
    "                torch.zeros(self.recurrent_num_layers, self.batch_size, self.hidden_size, device=device),\n",
    "                torch.zeros(self.recurrent_num_layers, self.batch_size, self.hidden_size, device=device)\n",
    "            )\n",
    "        return torch.zeros(self.recurrent_num_layers, self.batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize this network with values appropriate for the character prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chars = len(CHARACTERS)\n",
    "batch_size = 4\n",
    "\n",
    "char_rnn = CharRNN(n_chars, n_chars, batch_size, recurrent_layer_type=\"RNN\")\n",
    "if HAS_GPU:\n",
    "    char_rnn.cuda(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before each batch, we zero out the RNN hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: torch.Size([1, 4, 100])\n"
     ]
    }
   ],
   "source": [
    "max_window_size = 20\n",
    "gen = batch_sliding_window_generator(training_data, batch_size, max_window_size, gen_forever=False)\n",
    "batch, _ = next(gen)\n",
    "\n",
    "x_seq_tensor, y_tensor = batch_xy_to_tensor_xy(batch)\n",
    "x_char_tensor = x_seq_tensor.narrow(0, 0, 1)\n",
    "\n",
    "hidden = char_rnn.init_hidden()\n",
    "output, next_hidden = char_rnn(x_char_tensor, hidden)\n",
    "print(\"Output:\", output.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing to Train our Model\n",
    "We will create a helper function to convert the network predicted output back to a human readable character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch element 0: ('x', 48)\n",
      "Batch element 1: ('l', 66)\n",
      "Batch element 2: ('l', 66)\n",
      "Batch element 3: ('\\x02', 41)\n",
      "('_', 64)\n",
      "('o', 96)\n",
      "('B', 67)\n",
      "('P', 26)\n"
     ]
    }
   ],
   "source": [
    "def readable_from_output(output):\n",
    "    \"\"\"Convert network output predictions back to readable values.\"\"\"\n",
    "    top_n, top_i = output.topk(1)\n",
    "    batch_elems, _ = top_i[0].size()\n",
    "    batch_chars = []\n",
    "    for batch_elm_idx in range(batch_elems):\n",
    "        char_index = top_i[0][batch_elm_idx].item()\n",
    "        batch_char = INT2CHAR[char_index], char_index\n",
    "        batch_chars.append(batch_char)\n",
    "    return tuple(batch_chars)\n",
    "\n",
    "# What was predicted for each batch element?\n",
    "for batch_elem_idx, readable in enumerate(readable_from_output(output)):\n",
    "    print(\"Batch element {}: {}\".format(batch_elem_idx, readable))\n",
    "for batch_elem_idx, readable in enumerate(readable_from_output(y_tensor)):\n",
    "    print(readable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the network some examples, have it make predictions, and then inform the network when the predictions are correct.\n",
    "We have a classification problem, so Negative Log Likelihood loss is appropriate.\n",
    "\n",
    "For classifing input into `C` number of classes, the following loss functions are useful:\n",
    "\n",
    "* **Cross Entropy Loss**: [CrossEntropyLoss docs](https://pytorch.org/docs/stable/nn.html#crossentropyloss)\n",
    "* **Negative Log Likelihood Loss**: [NLLLoss docs](https://pytorch.org/docs/stable/nn.html#nllloss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each training loop will:\n",
    "\n",
    "0. Create input and target tensors\n",
    "0. Initialize a zerored hidden state\n",
    "0. Read each letter in and keep the hidden state for the next letter\n",
    "0. Compare the final output to the target\n",
    "0. Back-propagate\n",
    "0. Return the output and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(true_output_tensor, char_sequence_tensor, learning_rate = 0.005):\n",
    "    hidden = char_rnn.init_hidden()\n",
    "    \n",
    "    # Sets gradients of all model parameters to zero\n",
    "    char_rnn.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    hidden = char_rnn.init_hidden()\n",
    "    batch_seq_size, batch_size, num_classes = char_sequence_tensor.size()\n",
    "    for i in range(0, batch_seq_size):\n",
    "        output, hidden = char_rnn(char_sequence_tensor[:,i], hidden)\n",
    "        # diagnose training issues\n",
    "        #import pdb; pdb.set_trace()\n",
    "\n",
    "        loss += criterion(output.view(batch_size, -1), true_output_tensor[:,i])\n",
    "    loss.backward()\n",
    "    \n",
    "    for p in char_rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "    \n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our Model\n",
    "Let's train our model and check validation loss on each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize required variables\n",
    "n_chars = len(CHARACTERS)\n",
    "batch_size = 1\n",
    "char_rnn = CharRNN(n_chars, n_chars, batch_size, recurrent_layer_type=\"RNN\")\n",
    "if HAS_GPU:\n",
    "    char_rnn.cuda(device)\n",
    "\n",
    "# Helper function\n",
    "def time_since(since):\n",
    "    delta = time() - since\n",
    "    sec = int(delta)\n",
    "    mins = floor(sec / 60)\n",
    "    sec -= mins * 60\n",
    "    return \"{}m {:0>2d}s\".format(mins, sec)\n",
    "\n",
    "# Keep track of all the trainng that is done\n",
    "train_epoch_losses = []\n",
    "batch_iter_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable which can change in-between trainng\n",
    "n_epochs = 10\n",
    "print_every = 347\n",
    "max_window_size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-17-ee22ce9e0a51>(16)train()\n",
      "-> loss += criterion(output.view(batch_size, -1), true_output_tensor[:,i])\n",
      "(Pdb) output.view(batch_size, -1)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.]], grad_fn=<ViewBackward>)\n",
      "(Pdb) output.view(batch_size, -1).shape\n",
      "torch.Size([1, 100])\n",
      "(Pdb) output.view(batch_size, -1).topk(1)\n",
      "(tensor([[0.]], grad_fn=<TopkBackward>), tensor([[99]]))\n",
      "(Pdb) output.topk(1)\n",
      "(tensor([[[0.]]], grad_fn=<TopkBackward>), tensor([[[99]]]))\n",
      "(Pdb) true_output_tensor.shape\n",
      "torch.Size([15, 1, 100])\n",
      "(Pdb) output.shape\n",
      "torch.Size([1, 1, 100])\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "for epoch_idx in range(n_epochs):\n",
    "    # This generator will terminate when it finishes the file.\n",
    "    gen = batch_sliding_window_generator(\n",
    "        training_data, batch_size, max_window_size, output_seq=True, gen_forever=False)\n",
    "    for batch, _ in gen:\n",
    "        input_seq_tensor, loss_output_tensor = batch_xy_to_tensor_xyseq(batch)\n",
    "\n",
    "        pred_output, train_loss = train(loss_output_tensor, input_seq_tensor)\n",
    "        \n",
    "        # Print iter number, loss, name and guess\n",
    "        prediction, _ = zip(*readable_from_output(pred_output))\n",
    "        truth, _ = zip(*readable_from_output(true_output_tensor))\n",
    "        train_correct = []\n",
    "        for pred_idx, pred_val in enumerate(prediction):\n",
    "            if pred_val == truth[pred_idx]:\n",
    "                train_correct.append(1)\n",
    "            else:\n",
    "                train_correct.append(0)\n",
    "\n",
    "        train_accuracy = sum(train_correct)/len(train_correct)\n",
    "\n",
    "        if batch_iter_idx % print_every == 0:            \n",
    "            print(\"Epoch {:1d} {:.1f}%: iter {:5d} ({}) {:.5f} | Train-Acc: {:.2f}\".format(\n",
    "                epoch_idx, epoch_idx/n_epochs * 100, batch_iter_idx,\n",
    "                time_since(start), train_loss, train_accuracy))\n",
    "        batch_iter_idx += 1\n",
    "\n",
    "    # TODO: validation loss\n",
    "    # Add current loss avg to list of losses after each epoch\n",
    "    train_epoch_losses.append(train_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Training Process\n",
    "Plotting the historical loss from `train_epoch_losses` show how well the network is learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4d784a5240>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Batching Char-RNN Source Code Loss over Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Negative Log Likelihood\")\n",
    "plt.plot(train_epoch_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using User Specified Input\n",
    "\n",
    "Let's test this ourselves by supplying our own Python source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0002\n",
      "~~~~~Auto Completion~~~~~\n",
      "\u0002bbbbbbbbbb\n",
      "~~~~~max_len reached~~~~~\n"
     ]
    }
   ],
   "source": [
    "def evaluate(seq_tensor, hidden = char_rnn.init_hidden()):\n",
    "    \"\"\"Return an output character tensor, given an input character sequence tensor.\"\"\"\n",
    "    batch_seq_size, _, _ = seq_tensor.size()\n",
    "    \n",
    "    for i in range(0, batch_seq_size):\n",
    "        x_char_tensor = seq_tensor.narrow(0, i, 1)\n",
    "        output, hidden = char_rnn(x_char_tensor, hidden)\n",
    "    return output, hidden\n",
    "\n",
    "def predict(input_char_seq, max_len=10, max_window_size=None):\n",
    "    print(\"\".join(input_char_seq))\n",
    "    print(\"~~~~~Auto Completion~~~~~\")\n",
    "    with torch.no_grad():\n",
    "        print(\"\".join(input_char_seq), end=\"\")\n",
    "        seq_tensor = charseq_to_tensor(input_char_seq)\n",
    "        # expand the batch_size dimension to match char_rnn model\n",
    "        output, hidden = evaluate(seq_tensor.expand(-1, char_rnn.batch_size, -1))\n",
    "\n",
    "        for i in range(max_len):\n",
    "            # Suggestion: Maybe probabalistically choose using weights over all choices?\n",
    "            next_char = readable_from_output(output)[0][0]\n",
    "            if next_char == FILE_END:\n",
    "                return\n",
    "            print(next_char, end=\"\")\n",
    "            input_char_seq = input_char_seq + (next_char, )\n",
    "            if max_window_size is not None:\n",
    "                window_size = max_window_size\n",
    "            else:\n",
    "                window_size = len(input_char_seq)\n",
    "            seq_tensor = charseq_to_tensor(input_char_seq[-window_size:])\n",
    "            output, hidden = evaluate(seq_tensor.expand(-1, char_rnn.batch_size, -1))\n",
    "        print(\"\\n~~~~~max_len reached~~~~~\")\n",
    "\n",
    "# this is symbolic, to demonstrate that we have memorized the training data.\n",
    "CODE = (FILE_START,)\n",
    "predict(tuple(CODE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
